<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 18:40:38 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-61/HBASE-61.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-61] [hbase] Create an HBase-specific MapFile implementation</title>
                <link>https://issues.apache.org/jira/browse/HBASE-61</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;Today, HBase uses the Hadoop MapFile class to store data persistently to disk. This is convenient, as it&apos;s already done (and maintained by other people &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.gif&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;. However, it&apos;s beginning to look like there might be possible performance benefits to be had from doing an HBase-specific implementation of MapFile that incorporated some precise features.&lt;/p&gt;

&lt;p&gt;This issue should serve as a place to track discussion about what features might be included in such an implementation.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12386229">HBASE-61</key>
            <summary>[hbase] Create an HBase-specific MapFile implementation</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.png">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ryanobjc">ryan rawson</assignee>
                                    <reporter username="bryanduxbury">Bryan Duxbury</reporter>
                        <labels>
                    </labels>
                <created>Mon, 14 Jan 2008 23:20:49 +0000</created>
                <updated>Sun, 13 Sep 2009 22:24:09 +0000</updated>
                            <resolved>Wed, 25 Feb 2009 05:49:56 +0000</resolved>
                                                    <fixVersion>0.20.0</fixVersion>
                                    <component>io</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>8</watches>
                                                                                                            <comments>
                            <comment id="12558846" author="bryanduxbury" created="Mon, 14 Jan 2008 23:27:08 +0000"  >&lt;p&gt;Here&apos;s some of the ideas we&apos;re tossing around as a starter:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Exclude column family name from the file: Currently we store HStoreKeys, which are serialized to contain row, qualified cell name, and timestamp. However, seeing as how a given MapFile only ever belongs to one column family it&apos;s very wasteful to store the same column family name over and over again. In a custom implementation, we wouldn&apos;t have to save that data.&lt;/li&gt;
	&lt;li&gt;Separate indices for rows from qualified name and timestamp: Currently, the index in MapFiles is over all records, so the same row can appear in the index more than one time (differentiated by column name/timestamp). If the index just contained row keys, then we could store each row key exactly once, which would point to a record group of qualified names and timestamps (and values of course). Within the record group, there could be another separate small index on qualified name. This would again reduce the size of data stored, size of indices, and make it easier to do things like split regions lexically instead of skewed by cell count.&lt;/li&gt;
	&lt;li&gt;Use random rather than streaming reads: There is some indication that the existing MapFile implementation is optimized for streaming access; HBase supports random reads, which are therefore not efficient under MapFile. It would make sense for us to design our new implementation in such a way that it would be very cheap to do random access.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="12559105" author="tomwhite" created="Tue, 15 Jan 2008 16:35:35 +0000"  >&lt;p&gt;The current design of MapFile.Reader makes it difficult to write an in-memory implementation. For example, to implement next() it&apos;s no good having a copy of the keys and values in memory as you can&apos;t copy their values into the Writables passed into the next method. Perhaps Writable should have a readFields(Writable) method? Or maybe the API should change.&lt;/p&gt;

&lt;p&gt;To write an in-memory implementation with the current design, I think you would need to do it at a lower level and hold the data file bytes in memory. Keys and values would be reconstructed each time next() or get() was called, so this would be less efficient than an implementation that cached keys and values.&lt;/p&gt;</comment>
                            <comment id="12559195" author="stack" created="Tue, 15 Jan 2008 19:37:09 +0000"  >&lt;p&gt;We need a fast containsKey (Especially so if &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-29&quot; title=&quot;HStore#get and HStore#getFull may not return expected values by timestamp when there is more than one MapFile&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-29&quot;&gt;&lt;del&gt;HADOOP-2513&lt;/del&gt;&lt;/a&gt; goes in).  Would be sweet if backing implementation was able to satisfy the query out of a full index &amp;#8211; i.e. an index that had an entry for every key in the mapfile (expensive) &amp;#8211; or that tested membership against a bloom filter.&lt;/p&gt;</comment>
                            <comment id="12559201" author="jimk" created="Tue, 15 Jan 2008 19:46:46 +0000"  >&lt;p&gt;a fast containsKey could be based on bloom filters (at least it would tell you !containsKey) quickly.&lt;/p&gt;</comment>
                            <comment id="12559203" author="bryanduxbury" created="Tue, 15 Jan 2008 19:49:06 +0000"  >&lt;p&gt;I think it would make sense for us to maintain both a bloom filter and an index on row keys. That way, you can check the filter first to decide if you should check the index. Even if there&apos;s been deletions in the region that damage the filter, the index will still answer your question pretty quickly. We can maintain (re-create) the filter during compactions.&lt;/p&gt;

&lt;p&gt;I think we would see huge gains from having an always-on bloom filter, especially for sparser row spaces.&lt;/p&gt;</comment>
                            <comment id="12559322" author="bryanduxbury" created="Wed, 16 Jan 2008 01:12:03 +0000"  >&lt;p&gt;It would also be nice to get a row count quickly from a MapFile, or at least check if the MapFile was empty. Can&apos;t do that today.&lt;/p&gt;</comment>
                            <comment id="12559528" author="tomwhite" created="Wed, 16 Jan 2008 15:19:44 +0000"  >&lt;p&gt;If MapFile.Reader were an interface (or an abstract class with a no args constructor) then BloomFilterMapFile.Reader, HalfMapFileReader and caching Readers could be implemented as wrappers instead of in a static hierarchy. This would make it easier to mix and match readers (e.g. with or without caching) without passing all possible parameters in the constructor.&lt;/p&gt;</comment>
                            <comment id="12559655" author="cutting" created="Wed, 16 Jan 2008 20:40:21 +0000"  >&lt;p&gt;&amp;gt; Exclude column family name from the file [ ... ]&lt;/p&gt;

&lt;p&gt;The column family name could be stored in the SequenceFile&apos;s metadata, no?  MapFile&apos;s constructors don&apos;t currently permit one to specify metadata, but that&apos;d be easy to add.&lt;/p&gt;

&lt;p&gt;&amp;gt; There is some indication that the existing MapFile implementation is optimized for streaming access [ ... ]&lt;/p&gt;

&lt;p&gt;It shouldn&apos;t be.  The problem is that mapreduce, what&apos;s primarily used to benchmark and debug Hadoop, doesn&apos;t do any random access.  So it&apos;s easy for random-access-related performance problems to sneak into MapFile and HDFS.  Both Nutch and HBase depend on efficient random access from Hadoop, primarily through MapFile.  We need a good random-access benchmark that someone regularly executes.  Perhaps one could be added to the sort benchmark suite, since that is regularly run by Yahoo!?  Or someone else could start running regular HBase benchmarks on a grid somewhere?&lt;/p&gt;</comment>
                            <comment id="12559673" author="bryanduxbury" created="Wed, 16 Jan 2008 21:53:22 +0000"  >&lt;p&gt;Sometimes, it&apos;d be nice to iterate on the keys of a MapFile without actually reading the data. For instance, check out HStore#getClosestRowBefore - this seeks around checking keys and doesn&apos;t even use the value once it&apos;s been found. Every read to the underlying SequenceFile for that value is wasted.&lt;/p&gt;</comment>
                            <comment id="12559676" author="cutting" created="Wed, 16 Jan 2008 22:00:05 +0000"  >&lt;p&gt;&amp;gt; it&apos;d be nice to iterate on the keys of a MapFile without actually reading the data&lt;/p&gt;

&lt;p&gt;SequenceFile supports that, so it shouldn&apos;t be too hard to add a next(WritableComparable) method to the MapFile API, right?&lt;/p&gt;</comment>
                            <comment id="12561173" author="stack" created="Tue, 22 Jan 2008 00:01:14 +0000"  >&lt;p&gt;Bloom Filters:&lt;/p&gt;

&lt;p&gt;+ Turns out, particularly since the change where we now have a Memcache per Store rather than one for a whole Region, we know the number of elements we&apos;re about to flush out to a Store file.  Means we can pick an optimal bloom filter size.  Therefore, bloom filters could be enabled by default.&lt;br/&gt;
+ We currently provide a choice: General, Counting, and Dynamic.  I do not see where we would ever use anything but a General bloom filter (Counting adds deletions, dynamic allows sizing).  Therefore, I&apos;d suggest we remove choice of implementations.&lt;br/&gt;
+ Bloom filters are not as effective as they could be given that the most popular lookup will be for the &apos;latest&apos; version of a cell: i.e. the lookup is not for an explicit cell &amp;#8211; row/column/ts &amp;#8211; but for the most recent version of the cell.  So, bloom filters should be populated by row/column and probably not ts.  Will have to actually fetch the cell to learn its actual ts.&lt;/p&gt;

&lt;p&gt;Mapfile Indices:&lt;/p&gt;

&lt;p&gt;+ If index had an entry for every row/column/ts entry in a Store file/MapFile, we wouldn&apos;t need a bloom filter (But it would consume volumes more memory!)&lt;br/&gt;
+ Chatting w/ Bryan, mapfile indices could be kept in an LRU.  We&apos;d add a means of asking a mapfile for its index.  We&apos;d shove it into an LRU or into a Reference Map (For the latter, when memory was low, the index would be dropped and would be refetched on next access).&lt;/p&gt;</comment>
                            <comment id="12588116" author="jimk" created="Fri, 11 Apr 2008 21:04:36 +0000"  >&lt;p&gt;I ran some performance tests today and the results were not pretty.&lt;/p&gt;

&lt;p&gt;Doing 1,048,576 sequential writes through HBase onto the local file system achieved 3,620 writes per second.&lt;/p&gt;

&lt;p&gt;Writing 1,048,576 records sequentially into a MapFile onto the local file system was slightly better at 5,674 writes per second.&lt;/p&gt;</comment>
                            <comment id="12596617" author="stack" created="Wed, 14 May 2008 03:12:49 +0000"  >&lt;p&gt;TFile looks promising&lt;/p&gt;</comment>
                            <comment id="12636723" author="stack" created="Fri, 3 Oct 2008 20:02:10 +0000"  >&lt;p&gt;Started a wikipage for new file format discussion: &lt;a href=&quot;http://wiki.apache.org/hadoop/Hbase/NewFileFormat&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://wiki.apache.org/hadoop/Hbase/NewFileFormat&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="12666015" author="apurtell" created="Thu, 22 Jan 2009 00:49:08 +0000"  >&lt;p&gt;I see this on the agenda for the Hackathon on Jan 30. Maybe some of the goals of &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1024&quot; title=&quot;Rearchitect regionserver I/O&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1024&quot;&gt;&lt;del&gt;HBASE-1024&lt;/del&gt;&lt;/a&gt; regarding file level scaling and I/O efficiency can be incorporated here?&lt;/p&gt;</comment>
                            <comment id="12666024" author="streamy" created="Thu, 22 Jan 2009 01:14:07 +0000"  >&lt;p&gt;Andrew, I&apos;ve added it to the schedule.  There&apos;s 30 mins on TFile followed by 30 mins of general scalability, so &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-1024&quot; title=&quot;Rearchitect regionserver I/O&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-1024&quot;&gt;&lt;del&gt;HBASE-1024&lt;/del&gt;&lt;/a&gt; should be a good issue to transition the discussion.&lt;/p&gt;</comment>
                            <comment id="12666845" author="stack" created="Sat, 24 Jan 2009 06:50:28 +0000"  >&lt;p&gt;I like the idea of starting out with hbase-1024.  Its big picture goals.  Interesting though is reading recently bigtable slides, it said 100 regions of 100-200MBs per server (probably so can inmemory)?  Maybe the 100 is a misprint?  Should be a 1000?&lt;/p&gt;</comment>
                            <comment id="12666849" author="stack" created="Sat, 24 Jan 2009 07:17:28 +0000"  >&lt;p&gt;This is tfile patch adapted to hbase; tests that are very long running or that depend on the removed lzo have been disabled or worked on.&lt;/p&gt;</comment>
                            <comment id="12668692" author="stack" created="Fri, 30 Jan 2009 01:16:51 +0000"  >&lt;p&gt;This patch includes HTFile, the wrapper around TFile.  Also a HTFilePerformanceEvaluation that does same as MapFilePerformanceEvaluation.  We&apos;re writing about 3x faster with tfile but there is something wrong w/ our random accesses.  I&apos;m looking into it.&lt;/p&gt;</comment>
                            <comment id="12668695" author="stack" created="Fri, 30 Jan 2009 01:18:20 +0000"  >&lt;p&gt;Random-reading, here is a picture from there profiler showing where we spend all our time.  We&apos;re nexting through the tfile block that has the wanted key.&lt;/p&gt;</comment>
                            <comment id="12669362" author="stack" created="Sun, 1 Feb 2009 09:21:53 +0000"  >&lt;p&gt;Patch to tfile that will write longest key seen into file meta.  This longest key is then used constructing buffer used by tfile scanners.  The resultant scanner buffers should be good deal less than the maximum possible key size, the current buffer size used everytime a scanner is opened (even for the case where we are random-reading to get one value only).&lt;/p&gt;</comment>
                            <comment id="12669834" author="stack" created="Tue, 3 Feb 2009 01:26:19 +0000"  >&lt;p&gt;Testing, TFile is a good bit slower than MapFile if cells are ~100bytes or less and you are doing a random-access. Its slower even if you subsequently read 30 rows at the offset &amp;#8211; even if we use a tfile block size of 8k.  If cell values are 1k, tfile is faster than MF.&lt;/p&gt;

&lt;p&gt;So, after profiling and discussion on IRC, thought is that we need something like a stripped down tfile or even a new format altogether.  The attached patch is start of my stripping chunking and key and value streams out of TFile.  Not finished yet.  Intent is to keep most of the TFile API and the underlying block mechanism with its attendant block finding mechanism as well as all the metadata facility and index-on-the end but in the guts of tfile, there&apos;d be the DFSClient FSInput/OutputStream and blocks of byte arrays only.  The stripped down TFile is now called HFile.&lt;/p&gt;</comment>
                            <comment id="12670168" author="stack" created="Tue, 3 Feb 2009 23:20:46 +0000"  >&lt;p&gt;More stripping. This patch has HFile sort of working again (Its a hackup with ugly byte array copies that we need to remove). I was able to do some basic performance comparisons. If buffer size is 4k, then I can random access 10 byte cells as fast a MapFile. If cells are bigger, HFile outperforms MapFile; e.g. if cell is 100 bytes, HFile is 2x MapFile (These are extremely coarse tests going against local filesystem).&lt;/p&gt;

&lt;p&gt;Need to do more stripping. In particular implement Ryan Rawson idea of carrying HFile block in an nio ByteBuffer giving out new ByteBuffer &apos;views&apos; when a key or value is asked for rather than copy byte arrays.&lt;/p&gt;</comment>
                            <comment id="12670821" author="stack" created="Thu, 5 Feb 2009 16:38:09 +0000"  >&lt;p&gt;Latest version of the hfile patch.  Scanners work properly now.  Stripped down the API.  Actually need the SimpleBufferedInputStream  between tfile and DFSInputStream &amp;#8211; just with smaller buffer size &amp;#8211; for sake of increased concurrency.  Also need to change how we read so we read the whole block in rather than piecemeal it as tfile currently does.  The tfile is block based but reads on backing stream do not pull in whole blocks; it just reads whats needed.  This means that there is no whole block to cache if we only read a part and we&apos;re decompressing just what we need &amp;#8211; so it can be faster in certain circumstance &amp;#8211; but this behavior frustrates being able to cache on a block basis or more importantly decompressed blocks.&lt;/p&gt;

&lt;p&gt;I&apos;d work on this next but have been chatting with Ryan Rawson over last few days and he just sent me his rfile patch.  Going to help out on that effort for a while.&lt;/p&gt;</comment>
                            <comment id="12671060" author="stack" created="Fri, 6 Feb 2009 08:51:50 +0000"  >&lt;p&gt;Ryan checked in his rfile over here on github: &lt;a href=&quot;http://github.com/ryanobjc/hbase-rfile/tree/master&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://github.com/ryanobjc/hbase-rfile/tree/master&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Its up on github so more than one person can bang on it.  Notion is first to test rfile vs tfile vs mapfile (I checked in latest hfile into github for contrast) and then whichever wins, make a patch out of the github for this issue.&lt;/p&gt;

&lt;p&gt;I added to github an evaluate RFile using PE.  RFile is ahead of MF it looks like using an 8k buffer and 10byte cells.  Tomorrow will do more work ensuring all files are returning what they are supposed to and will try compare on dfs.&lt;/p&gt;

&lt;p&gt;Talked to AJ also to day.  Suggested playing with pread &amp;#8211; DFSDataIS has one &amp;#8211; so file can be more &apos;live&apos;.  Suggested also removing buffering on DFSDIS since we&apos;re reading in blocks and suggested we also look at receive socket buffer size &amp;#8211; maybe add our own socket factory and if block size &amp;lt; socket receive buffer size, use the smaller.&lt;/p&gt;</comment>
                            <comment id="12671368" author="stack" created="Fri, 6 Feb 2009 23:16:49 +0000"  >&lt;p&gt;Here are some numbers comparing file formats: &lt;a href=&quot;http://wiki.apache.org/hadoop/Hbase/NewFileFormat/Performance&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://wiki.apache.org/hadoop/Hbase/NewFileFormat/Performance&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I tried making DFSDataInputStream work without buffering &amp;#8211; that&apos;d help rfile &amp;#8211; but seems like stream needs to be markable so it wouldn&apos;t work w/o a bunch of reworking.&lt;/p&gt;

&lt;p&gt;I also tried pread.  That made a different improving rfile numbers by about 10%.&lt;/p&gt;</comment>
                            <comment id="12671388" author="stack" created="Sat, 7 Feb 2009 01:31:55 +0000"  >&lt;p&gt;I added concurrent read numbers to the end of this page: &lt;a href=&quot;http://wiki.apache.org/hadoop/Hbase/NewFileFormat/Performance&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://wiki.apache.org/hadoop/Hbase/NewFileFormat/Performance&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="12673163" author="stack" created="Fri, 13 Feb 2009 07:09:42 +0000"  >&lt;p&gt;HFile is all done but for bloom filters (compression, metadata, comparators, etc). Might wait on BF for moment.  Work is ongoing over in &lt;a href=&quot;http://github.com/ryanobjc/hbase-rfile/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://github.com/ryanobjc/hbase-rfile/&lt;/a&gt; (Ryan and Stack).  Next is making hbase use hfile.&lt;/p&gt;</comment>
                            <comment id="12675631" author="stack" created="Sun, 22 Feb 2009 08:09:55 +0000"  >&lt;p&gt;Assigning to Ryan (He did hfile).&lt;/p&gt;</comment>
                            <comment id="12676122" author="ryanobjc" created="Mon, 23 Feb 2009 23:35:37 +0000"  >&lt;p&gt;This is a complete implemention of HFile plugged into hbase, diffed against the current trunk. The full source is visible at &lt;a href=&quot;http://github.com/ryanobjc&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://github.com/ryanobjc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Thanks to Stack who did a majority of the integration and test work.&lt;/p&gt;</comment>
                            <comment id="12676145" author="stack" created="Tue, 24 Feb 2009 00:37:40 +0000"  >&lt;p&gt;I&apos;m +1 on a commit (All tests pass for me).  There is work to do stil integration &amp;#8211; in particular mapping the HColumnDescriptor configurations to match new hfile for bloomfilters, compression, and blocksizing &amp;#8211; but I&apos;d suggest we do these as separate issues; the patch is big enough already.&lt;/p&gt;

&lt;p&gt;Primitive performance eval. shows random reads up by about 60%, writes up about 25% but scans are down.  Will do some profiling over next few days.&lt;/p&gt;

&lt;p&gt;Other notes on the patch:&lt;/p&gt;

&lt;p&gt;+ The change to hbase-site.xml is not yet hooked up.&lt;br/&gt;
+ This patch breaks binary keys because it undoes the ugly stuff we did to make them work.  Will fix again when we address hbase-859 &amp;#8211; thats next.  In other words, this patch has already started the reworking of HStoreKey removing all the crap where every key had a HREgionInfo reference.  One thing in particular that it adds is rawcomparator comparing store keys; that is, no object instantiation.. pure byte compare).&lt;br/&gt;
+ The patch is basically a rewrite from HStore down.  A few files were renamed because they changed so much &amp;#8211; HStore becomes Store, HStoreFile becomes StoreFile, etc.&lt;br/&gt;
+ Some pieces of this patch are taken from tfile, hadoop-3315.  In particular the hfile tests and much of the compression facility: e.g. BoundedRangeFileInputStream, and Compression types.&lt;br/&gt;
+ A few files are missing apache license &amp;#8211; we can add one when we commit (simple block cache).&lt;/p&gt;</comment>
                            <comment id="12676457" author="jdcryans" created="Wed, 25 Feb 2009 00:18:22 +0000"  >&lt;p&gt;Some tests I did:&lt;/p&gt;

&lt;p&gt;Unit tests on my Ubuntu desktop:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
BUILD SUCCESSFUL
Total time: 25 minutes 39 seconds
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;11 nodes cluster (2.0GHz CPU, 1GB RAM, 2*80GB HDD JBOD PATA)&lt;br/&gt;
PE ran from the Master node:&lt;/p&gt;

&lt;p&gt;HFile&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Finished sequentialWrite in 484020ms at offset 0 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1048576 rows  2166 rows/sec
HBase is restarted and I waited &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; all compactions to occur
Finished scan in 166626ms at offset 0 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1048576 rows  6293 rows/sec
Finished randomRead in 2711788ms at offset 0 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1048576 rows  387 rows/sec
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;MapFile&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Finished sequentialWrite in 496937ms at offset 0 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1048576 rows  2110 rows/sec
HBase is restarted and I waited &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; all compactions to occur
Finished scan in 153011ms at offset 0 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1048576 rows  6853 rows/sec
Finished randomRead in 4270211ms at offset 0 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1048576 rows 246 rows/sec
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So, on this setup, reads are way up, writes are a bit up and scans are a tiny bit down. IMO this is good for a commit if issues stated by Stack are addressed in other jiras.&lt;/p&gt;

&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="12676519" author="stack" created="Wed, 25 Feb 2009 05:49:56 +0000"  >&lt;p&gt;Committed.  Thanks for the patch Ryan (And thanks J-D for testing &amp;#8211; I&apos;ve made separate issues for hooking up configuring hfile).&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="12414769">HBASE-1200</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310010">
                    <name>Incorporates</name>
                                            <outwardlinks description="incorporates">
                                        <issuelink>
            <issuekey id="12384805">HBASE-236</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12414411">HBASE-1192</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12385541">HBASE-68</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12416456">HBASE-1249</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12400801" name="HBASE-83.patch" size="677987" author="ryanobjc" created="Mon, 23 Feb 2009 23:35:37 +0000"/>
                            <attachment id="12399081" name="cpucalltreetfile.html" size="674232" author="stack" created="Fri, 30 Jan 2009 01:18:20 +0000"/>
                            <attachment id="12399321" name="hfile.patch" size="394100" author="stack" created="Tue, 3 Feb 2009 01:26:19 +0000"/>
                            <attachment id="12399401" name="hfile2.patch" size="395943" author="stack" created="Tue, 3 Feb 2009 23:20:46 +0000"/>
                            <attachment id="12399576" name="hfile3.patch" size="383575" author="stack" created="Thu, 5 Feb 2009 16:38:09 +0000"/>
                            <attachment id="12399230" name="longestkey.patch" size="2088" author="stack" created="Sun, 1 Feb 2009 09:21:53 +0000"/>
                            <attachment id="12398634" name="tfile.patch" size="364033" author="stack" created="Sat, 24 Jan 2009 07:17:28 +0000"/>
                            <attachment id="12399080" name="tfile3.patch" size="409860" author="stack" created="Fri, 30 Jan 2009 01:16:51 +0000"/>
                    </attachments>
                <subtasks>
                            <subtask id="12391507">HBASE-517</subtask>
                            <subtask id="12391508">HBASE-518</subtask>
                            <subtask id="12391509">HBASE-519</subtask>
                            <subtask id="12396953">HBASE-647</subtask>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>8.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Tue, 15 Jan 2008 16:35:35 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>31658</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10342"><![CDATA[Incompatible change]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 43 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0h3y7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>97902</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310222" key="com.atlassian.jira.ext.charting:timeinstatus">
                        <customfieldname>Time in Status</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        </customfields>
    </item>
</channel>
</rss>