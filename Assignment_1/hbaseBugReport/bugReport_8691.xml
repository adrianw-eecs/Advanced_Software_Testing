<!-- 
RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Fri Dec 16 19:57:37 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/si/jira.issueviews:issue-xml/HBASE-8691/HBASE-8691.xml?field=key&amp;field=summary
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>6.3.4</version>
        <build-number>6332</build-number>
        <build-date>15-08-2014</build-date>
    </build-info>

<item>
            <title>[HBASE-8691] High-Throughput Streaming Scan API</title>
                <link>https://issues.apache.org/jira/browse/HBASE-8691</link>
                <project id="12310753" key="HBASE">HBase</project>
                    <description>&lt;p&gt;I&apos;ve done some working testing various ways to refactor and optimize Scans in HBase, and have found that performance can be dramatically increased by the addition of a streaming scan API.  The attached code constitutes a proof of concept that shows performance increases of almost 4x in some workloads.&lt;/p&gt;

&lt;p&gt;I&apos;d appreciate testing, replication, and comments.  If the approach seems viable, I think such an API should be built into some future version of HBase.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12651048">HBASE-8691</key>
            <summary>High-Throughput Streaming Scan API</summary>
                <type id="4" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/improvement.png">Improvement</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="prattrs">Sandy Pratt</assignee>
                                    <reporter username="prattrs">Sandy Pratt</reporter>
                        <labels>
                            <label>perfomance</label>
                            <label>scan</label>
                    </labels>
                <created>Wed, 5 Jun 2013 08:07:31 +0000</created>
                <updated>Fri, 20 Feb 2015 18:48:40 +0000</updated>
                                            <version>0.95.0</version>
                                                    <component>Scanners</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>28</watches>
                                                                <comments>
                            <comment id="13675689" author="prattrs" created="Wed, 5 Jun 2013 08:08:39 +0000"  >&lt;p&gt;See README for details on how to apply this code to an existing environment.&lt;/p&gt;</comment>
                            <comment id="13675729" author="stack" created="Wed, 5 Jun 2013 09:13:24 +0000"  >&lt;p&gt;Thanks for looking into this Sandy.&lt;/p&gt;

&lt;p&gt;Now come the dumb questions.&lt;/p&gt;

&lt;p&gt;You did it as servlet just because this was easiest way of putting up a new socket on a regionserver over which you could do this new streaming protocol?&lt;/p&gt;

&lt;p&gt;Similarily, regionserver already has an Http Server instance to which we could mount the new servlet but it was just expediency that has you create the Server in StreamHRegionServer?&lt;/p&gt;

&lt;p&gt;(Pardon the dumb assertions above &amp;#8211; just trying to make sure I can grok better what is going on)&lt;/p&gt;

&lt;p&gt;I need to measure what happens when we put our new framing of results &amp;#8211; where we send a pb of metadata followed by blocks of KVs &amp;#8211; over your stream.  My guess is we should see same speedup (only using blocks of kvs, we can have compressed/prefix-encoded blocks of kvs on the wire) even though there will be some &quot;stutter&quot; while we compose the cellblocks server-side.  Hopefully the stutter won&apos;t be noticed &amp;#8211; as long as we keep the stream filled w/ data.&lt;/p&gt;

&lt;p&gt;This is great.&lt;/p&gt;</comment>
                            <comment id="13675977" author="yuzhihong@gmail.com" created="Wed, 5 Jun 2013 14:44:21 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
YourProtobuf pb = YourProtobuf.newBuilder().mergeFrom(b).build();
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Mind showing us YourProtobuf class ?&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="13676166" author="prattrs" created="Wed, 5 Jun 2013 17:48:24 +0000"  >&lt;p&gt;Stack,&lt;/p&gt;

&lt;p&gt;Perfectly normal questions that I should have addressed in the initial&lt;br/&gt;
post.&lt;/p&gt;

&lt;p&gt;I used the servlet as an expedient way of adding an API to HBase without&lt;br/&gt;
taking the time to fully understand how HRegionServer uses its associated&lt;br/&gt;
RPC server.  I do think that a streaming scan API should be added to the&lt;br/&gt;
normal HRegionServer interface, but I don&apos;t know how to do that yet, and&lt;br/&gt;
it didn&apos;t seem critical to validating my performance hypothesis.  I also&lt;br/&gt;
wanted to make sure that there&apos;s no point where we wait for the full&lt;br/&gt;
result before starting to return to the client.&lt;/p&gt;

&lt;p&gt;I&apos;m not familiar with the work you&apos;re referring to about framing of&lt;br/&gt;
results, but I did find that it&apos;s critical to do as little encoding of the&lt;br/&gt;
stream as possible.  For example, I tried one approach where I&lt;br/&gt;
deserialized the cell on the server, then re-encapsulated it and send it&lt;br/&gt;
down to the client.  That was apparently too much work in a tight loop,&lt;br/&gt;
and my performance wasn&apos;t much better that with a normal scan.  Using the&lt;br/&gt;
length-encoded byte stream had a huge impact on performance for me.&lt;br/&gt;
Obviously there&apos;s only so many cycles to spend between getting the result&lt;br/&gt;
from the InternalScanner and putting it on the wire before you start&lt;br/&gt;
starving the pipe to the client, but I was surprised at just how few there&lt;br/&gt;
actually are.  I would have thought there was time to muck around with&lt;br/&gt;
protobuf, but no.&lt;/p&gt;

&lt;p&gt;One thing I left on the table here is pushing the output stream down to&lt;br/&gt;
InternalScanner so that it can stream results directly to the client. As&lt;br/&gt;
is, it marshals a batch and then puts them on the wire (I tested with scan&lt;br/&gt;
caching 5000 and scan batch 5000).  That&apos;s potentially inefficient, I&lt;br/&gt;
think.&lt;/p&gt;

&lt;p&gt;Sandy&lt;/p&gt;


</comment>
                            <comment id="13676173" author="prattrs" created="Wed, 5 Jun 2013 17:54:22 +0000"  >&lt;p&gt;Ted,&lt;/p&gt;

&lt;p&gt;It&apos;s a place-holder for a client-specified decode of the cell.  I arguably&lt;br/&gt;
should have made it a byte array, but the result I reported used protobuf&lt;br/&gt;
serialization, so I changed the name to a place holder and left it at&lt;br/&gt;
that.  &lt;/p&gt;

&lt;p&gt;If you change RecordReceiver to this:&lt;/p&gt;

&lt;p&gt;package org.apache.hadoop.hbase.client;&lt;/p&gt;

&lt;p&gt;public interface RecordReceiver &lt;/p&gt;
{

	public int getNumScanned();
	
	public void receive(byte[] msg);
}


&lt;p&gt;then the rest should work itself out.&lt;/p&gt;

&lt;p&gt;Does that answer your question?&lt;/p&gt;

&lt;p&gt;Sandy&lt;/p&gt;



</comment>
                            <comment id="13676177" author="yuzhihong@gmail.com" created="Wed, 5 Jun 2013 17:57:59 +0000"  >&lt;p&gt;I see.&lt;/p&gt;

&lt;p&gt;Thanks Sandy.&lt;/p&gt;</comment>
                            <comment id="13676269" author="giacomotaylor" created="Wed, 5 Jun 2013 19:32:49 +0000"  >&lt;p&gt;Interesting ideas, Sandy. We&apos;d love to leverage this down the road in Phoenix (&lt;a href=&quot;https://github.com/forcedotcom/phoenix&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://github.com/forcedotcom/phoenix&lt;/a&gt;). As a simple, first use case, we&apos;d love to get streaming support for BLOB, CLOB types. If you want a place for your alternate client API to live, take a look at Phoenix.&lt;/p&gt;</comment>
                            <comment id="13676283" author="stack" created="Wed, 5 Jun 2013 20:02:26 +0000"  >&lt;blockquote&gt;&lt;p&gt;...but I don&apos;t know how to do that yet, and it didn&apos;t seem critical to validating my performance hypothesis.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Makes sense.  Nice hack starting Server and getting it going as a Servlet.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;...but I did find that it&apos;s critical to do as little encoding of the stream as possible.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This is interesting.  Compressing or doing prefix encoding, we will want to put KVs together in blocks of 32k or so.  Your findings that....&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;...but I was surprised at just how few there actually are. I would have thought there was time to muck around with protobuf, but no.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;... would seem to indicate that composing the blocks of prefix-encoded or compressed kvs would put us back to the send-pause-send-pause step function.&lt;/p&gt;

&lt;p&gt;But what do you mean when you say this:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I tested with scan caching 5000 and scan batch 5000&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Were you batching up 5k kvs before writing them out on the wire?&lt;/p&gt;

&lt;p&gt;As is, our rpc is not amenable at all to streaming.  There is one call and then it has a single result (or error).  Both call and result have their total size as effectively the first thing we transmit.  Introducing a protocol where size is not known and the results come in until an End-of-Stream marker is sent will be interesting to interweave into what we currently have; maybe it would be better to do as you do and just do new protocol over another port.  Let me take a looksee.&lt;/p&gt;

&lt;p&gt;Good on you Sandy.&lt;/p&gt;
</comment>
                            <comment id="13676292" author="prattrs" created="Wed, 5 Jun 2013 20:13:13 +0000"  >&lt;p&gt;&amp;gt; Were you batching up 5k kvs before writing them out on the wire?&lt;/p&gt;

&lt;p&gt;Correct.  I haven&apos;t experimented with other scanner caching settings yet (pertaining to the InternalScanner).&lt;/p&gt;
</comment>
                            <comment id="13676312" author="stack" created="Wed, 5 Jun 2013 20:30:37 +0000"  >&lt;blockquote&gt;&lt;p&gt;Correct.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Oh, and your kvs were 200-2000 bytes.....then that would seem to indicate that I should be able to do some kv block building before putting it on the wire &amp;#8211; as long as it didn&apos;t take too long doing prefix encoding or compressing.  I will experiment.  Good on you Sandy.&lt;/p&gt;</comment>
                            <comment id="13676540" author="lhofhansl" created="Thu, 6 Jun 2013 00:38:36 +0000"  >&lt;p&gt;Cool! This is solely an improvement of the client/server communication, not of the internal scanner framework (which I had spent a bit of time on).&lt;/p&gt;</comment>
                            <comment id="13677639" author="enis" created="Thu, 6 Jun 2013 23:03:32 +0000"  >&lt;p&gt;This looks very promising from the POC. &lt;br/&gt;
It seems that we can achieve this from purely client side changes. We can do a buffer of scan results, that when the scanner is opened, a thread continuously tries to fill, while the application processes the results. However, this will probably still not be able to achieve the same performance for pure streaming from RS. &lt;br/&gt;
Alternatively, for each scanner, we can open a streaming thread in RS (like the DataStreamer in hdfs) to pump data to the socket until the socket buffer is full as in this patch. Yet another thing we can try is to keep the current scan semantics, but each next() will trigger a prefetch to block cache. &lt;/p&gt;</comment>
                            <comment id="13677684" author="lhofhansl" created="Fri, 7 Jun 2013 00:09:30 +0000"  >&lt;p&gt;I hacked up a patch for the first some time ago (still using HBase RPC, but keeping it going via a 2nd thread in the ClientScanner).&lt;br/&gt;
Let me see whether I can find, but the principle is simple.&lt;/p&gt;</comment>
                            <comment id="13679652" author="prattrs" created="Mon, 10 Jun 2013 17:24:24 +0000"  >&lt;p&gt;Enis,&lt;/p&gt;

&lt;p&gt;One of the things I tested before I arrived at the streaming approach is a&lt;br/&gt;
producer-consumer queue on the client side, and/or on the server side.  On&lt;br/&gt;
the client side, using a thread to call next as often as possible showed&lt;br/&gt;
some modest speedup (about 10-15% depending on scanner caching).  When&lt;br/&gt;
used on the server side, a P/C queue was detrimental to performance, which&lt;br/&gt;
surprised me.  My guess is that the overhead of synchronization is too&lt;br/&gt;
much.&lt;/p&gt;

&lt;p&gt;Regarding the block cache, IIRC I set it to off in the Scan object in my&lt;br/&gt;
code.  It doesn&apos;t look like the internal scanner has any trouble keeping&lt;br/&gt;
up, regardless.  The main problem seemed to be the cost of my loop on the&lt;br/&gt;
server side.&lt;/p&gt;

&lt;p&gt;Sandy&lt;/p&gt;

</comment>
                            <comment id="13679657" author="prattrs" created="Mon, 10 Jun 2013 17:28:27 +0000"  >&lt;p&gt;Lars,&lt;/p&gt;

&lt;p&gt;One of the first things I tried was a producer/consumer queue with the&lt;br/&gt;
idea of having a thread call next as often as possible.ï¿½  I found a small&lt;br/&gt;
speedup from using that approach on the client side, and a performance&lt;br/&gt;
loss using it on the server side.  What results did you find with your&lt;br/&gt;
patch?&lt;/p&gt;

&lt;p&gt;Sandy&lt;/p&gt;



</comment>
                            <comment id="13679685" author="jxiang" created="Mon, 10 Jun 2013 17:52:42 +0000"  >&lt;blockquote&gt;&lt;p&gt;and a performance loss using it on the server side.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;We have considered prefetching in both the client side and the server side, and decided to start with the server side.  &lt;a href=&quot;https://issues.apache.org/jira/browse/HBASE-8420&quot; title=&quot;Port  HBASE-6874  Implement prefetching for scanners from 0.89-fb&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HBASE-8420&quot;&gt;&lt;del&gt;HBASE-8420&lt;/del&gt;&lt;/a&gt; handles server side prefetching (ported from 0.89, but with some difference). Based on my testing using ycsb, it does have about 6.5% performance gain.  If the client side spends more time with the results, the performance gain should be more due to the parallelism. I was wondering how you got a performance loss, context switching?&lt;/p&gt;</comment>
                            <comment id="13679710" author="prattrs" created="Mon, 10 Jun 2013 18:06:13 +0000"  >&lt;p&gt;&amp;gt; I was wondering how you got a performance loss, context switching?&lt;/p&gt;

&lt;p&gt;I think it was probably memory and cache synchronization, but that&apos;s just a guess.  It could have been due to wrapping results in protobuf (but note there was a separate thread calling next concurrently).  This was in the context of the streaming servlet BTW, not a normal RPC.&lt;/p&gt;

&lt;p&gt;Rather than try to explain in English, the code looked like this:&lt;/p&gt;

&lt;p&gt;		final long scannerId = hRegionServer.openScanner(regionName, scan);&lt;/p&gt;

&lt;p&gt;		final ArrayBlockingQueue&amp;lt;Result[]&amp;gt; cache = new ArrayBlockingQueue&amp;lt;Result[]&amp;gt;(5);&lt;/p&gt;

&lt;p&gt;		final Thread producer = new Thread() {&lt;br/&gt;
			@Override&lt;br/&gt;
			public void run() {&lt;br/&gt;
				try {&lt;br/&gt;
					while (true) {&lt;br/&gt;
						Result[] results = hRegionServer.next(scannerId, BATCH_SIZE);&lt;br/&gt;
						cache.put(results);&lt;br/&gt;
						if (results == null || results.length == 0) &lt;/p&gt;
{
							break;
						}
&lt;p&gt;					}&lt;br/&gt;
				} catch (Exception e) &lt;/p&gt;
{
					throw new RuntimeException(e);
				}
&lt;p&gt;			}&lt;br/&gt;
		};&lt;/p&gt;

&lt;p&gt;		producer.start();&lt;/p&gt;

&lt;p&gt;		long numRecords = 0;&lt;/p&gt;

&lt;p&gt;		try {&lt;br/&gt;
			while (true) {&lt;br/&gt;
				Result[] res = cache.take();&lt;br/&gt;
				if (res == null) &lt;/p&gt;
{
					EventResult.Builder eos = EventResult.newBuilder();
					eos.setEndOfScan(true);
					eos.setNumRecords(numRecords);
					eos.build().writeDelimitedTo(resp.getOutputStream());
					break;
				}
&lt;p&gt; else if (res.length == 0) &lt;/p&gt;
{
					EventResult.Builder eor = EventResult.newBuilder();
					eor.setEndOfRegion(true);
					eor.setNumRecords(numRecords);
					eor.build().writeDelimitedTo(resp.getOutputStream());
					break;
				}
&lt;p&gt; else {&lt;br/&gt;
					for (Result r : res) &lt;/p&gt;
{
						byte[] b = r.getValue(..., ...);
						MyPB.Builder builder = MyPB.newBuilder();
						builder.mergeFrom(b);
						MyPB pb = builder.build();
						EventResult.Builder er = EventResult.newBuilder();
						er.setPbEvent(pb);
						er.build().writeDelimitedTo(resp.getOutputStream());
						numRecords++;
					}
&lt;p&gt;				}&lt;br/&gt;
			}&lt;br/&gt;
		} catch (InterruptedException e) &lt;/p&gt;
{
			throw new RuntimeException(e);
		}
&lt;p&gt; finally &lt;/p&gt;
{
			resp.getOutputStream().close();
		}</comment>
                            <comment id="13679742" author="lhofhansl" created="Mon, 10 Jun 2013 18:30:48 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=prattrs&quot; class=&quot;user-hover&quot; rel=&quot;prattrs&quot;&gt;Sandy Pratt&lt;/a&gt; Need to see if that patch still applies. It wasn&apos;t doing next calls as frequent as possible, but rather interleaving client and server work (it worked together with scanner caching).&lt;/p&gt;</comment>
                            <comment id="13682705" author="prattrs" created="Thu, 13 Jun 2013 20:48:01 +0000"  >&lt;p&gt;I noticed when doing some more testing that I&apos;m returning only a partial Result in the stream case, but the full Result in the control cases.  That means the stream result doesn&apos;t have to transfer the rowkey (x3) and a couple of timestamps.  When I correct the test to return the full Result, using DataOutputBuffer/DataInputBuffer to serialize and deserialize, the stream case is about 2x faster than the RPC cases (rather than 4x faster).  I think it&apos;s still worth looking at for a 2x speedup.&lt;/p&gt;

&lt;p&gt;Unfortunately, I can&apos;t figure out how to make Hive work with an event driven interface.  Since my customers use Hive primarily, I might have to put this on the back burner for now.  I hope somebody finds it useful.&lt;/p&gt;</comment>
                            <comment id="13708855" author="prattrs" created="Mon, 15 Jul 2013 19:24:13 +0000"  >&lt;p&gt;Since my last comment, I&apos;ve worked out some issues around integrating the streaming scan API with Hive, and I&apos;ve pushed it out on an experimental basis to a production cluster for testing.  End-to-end, in a table scan situation, the streaming scan API turns out to be about 45% faster than the RPC scan API (a full table scan of my dataset took 31 about minutes with the streaming API versus about 45 minutes with the RCP API).&lt;/p&gt;

&lt;p&gt;Some of the tweaking I had to do to get to that point:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Refactored the streaming client scanner to conform to the standard AbstractClientScanner API (I had used an event-driven approach previously, where clients registered an &quot;onMessage&quot; interface and hit go)&lt;/li&gt;
	&lt;li&gt;Created a TableInputFormat/RecordReader/etc. that leverages the new API&lt;/li&gt;
	&lt;li&gt;Profiled my custom SerDe to iron out some surprising hotpots&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;As noted earlier, I looks like performance when streaming from the RS is highly dependent on keeping the pipe saturated.  Too much latency in any particular spot will cause bubbles, which kills performance.  As written, my SerDe was wasting too many cycles doing date formatting and initializing HashMaps (they seem to make a system call to srand).&lt;/p&gt;

&lt;p&gt;Once I ironed those issues out, I did a comparison between the streaming scan API and the RPC scan API, both using the newly optimized SerDe, which is where I found the 45% performance improvement.  If it&apos;s true that latency is key to performance here, that delta might go up with more modern CPUs (I have Xeon 5450s currently) as the overhead of Hive and the SerDe decrease relative to network speed.&lt;/p&gt;
</comment>
                            <comment id="13804430" author="yuzhihong@gmail.com" created="Thu, 24 Oct 2013 17:21:15 +0000"  >&lt;p&gt;@Sandy:&lt;br/&gt;
Were there any issues uncovered from the deployment with streaming API ?&lt;/p&gt;

&lt;p&gt;Are you able to produce patch for trunk ?&lt;/p&gt;

&lt;p&gt;Cheers&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12776140">HBASE-13071</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12586266" name="HRegionServlet.java" size="345" author="prattrs" created="Wed, 5 Jun 2013 08:08:39 +0000"/>
                            <attachment id="12586267" name="README.txt" size="8470" author="prattrs" created="Wed, 5 Jun 2013 08:08:39 +0000"/>
                            <attachment id="12586268" name="RecordReceiver.java" size="181" author="prattrs" created="Wed, 5 Jun 2013 08:08:39 +0000"/>
                            <attachment id="12586274" name="ScannerTest.java" size="5365" author="prattrs" created="Wed, 5 Jun 2013 08:17:38 +0000"/>
                            <attachment id="12586270" name="StreamHRegionServer.java" size="1338" author="prattrs" created="Wed, 5 Jun 2013 08:08:39 +0000"/>
                            <attachment id="12586271" name="StreamReceiverDirect.java" size="3995" author="prattrs" created="Wed, 5 Jun 2013 08:08:39 +0000"/>
                            <attachment id="12586275" name="StreamServletDirect.java" size="2846" author="prattrs" created="Wed, 5 Jun 2013 08:18:33 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>7.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
                        <customfieldname>Date of First Response</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>Wed, 5 Jun 2013 09:13:24 +0000</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>331374</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 8 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1l61z:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>331706</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>